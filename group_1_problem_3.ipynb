{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPtr7QBdxGYJlsIc2a4AYZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbermudez13/eel4815_final_coding_assignment/blob/main/group_1_problem_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qgv3CqljS8G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "881a0aff-65f5-48ec-82fe-f3fdde9f3d33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#### pre-process the data\\nx_train -= np.mean(x_train)\\nx_train /= np.std(x_train)\\n\\nx_test -= np.mean(x_test)\\nx_test /= np.std(x_test)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "\"\"\"\n",
        "This is a regression model. \n",
        "N is the number of features in each training or testing example. \n",
        "K is the number of units in each of the hidden layers. This number need not be fixed for both layers. \n",
        "\n",
        "For regression, M=1.\n",
        "M = 10 dataset  \n",
        "\"\"\"\n",
        "number_of_feature = 784\n",
        "number_of_units_in_hidden_layer = 60000\n",
        "#### load the dataset\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) =  tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\"\"\"\n",
        "#### pre-process the data\n",
        "x_train -= np.mean(x_train)\n",
        "x_train /= np.std(x_train)\n",
        "\n",
        "x_test -= np.mean(x_test)\n",
        "x_test /= np.std(x_test)\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### construct the NN regression model\n",
        "NN_regression_model = tf.keras.Sequential()\n",
        "# define layer\n",
        "hidden_layer_1 = layers.Dense(units=number_of_units_in_hidden_layer, activation='relu')\n",
        "# add layer to the model\n",
        "NN_regression_model.add(hidden_layer_1)\n",
        "\"\"\"\n",
        "# define layer\n",
        "hidden_layer_2 = layers.Dense(units=number_of_units_in_hidden_layer, activation='relu')\n",
        "# add layer to the model\n",
        "NN_regression_model.add(hidden_layer_2)\"\n",
        "\"\"\"\n",
        "# define layer\n",
        "output_layer = layers.Dense(units=100, activation=None)\n",
        "# add layer to the model\n",
        "NN_regression_model.add(output_layer)\n",
        "\n",
        "##NN_regression_model.add(layers.Dense(.001, activation='relu'))\n",
        "\n",
        "print(\"break\")\n",
        "\n",
        "#### specify optimizer - lets use SGD with learning rate of 0.001.\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\n",
        "\n",
        "#### specify the number of epochs and batch size\n",
        "epochs     = 40\n",
        "batch_size = 100\n",
        "\n",
        "#### compile the model\n",
        "NN_regression_model.compile(optimizer=optimizer, loss='mse', metrics='mse') # mean absolute error\n",
        "\n",
        "\n",
        "\n",
        "##softmax reLU\n",
        "##grid search: losses optimization\n",
        "##ADAM vs SGD // CE vs MSE\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJdxnMRWkRY-",
        "outputId": "d0b6311a-5732-4dd0-d79e-4fd3dc92b6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "break\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #### train the whole batch for 40 epochs\n",
        "NN_regression_model.fit(x_train, y_train, epochs=epochs, batch_size = batch_size, verbose=1)\n",
        "train_error_mse,_ = NN_regression_model.evaluate(x_train, y_train)\n",
        "test_error_mse ,_ = NN_regression_model.evaluate(x_test, y_test)\n",
        "print(\"MSE on training data = {} ; MSE of testing data = {}\".format(train_error_mse, test_error_mse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BQkLCfxtkU8l",
        "outputId": "47a9a11a-d19a-401c-a122-56f59920bc6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "600/600 [==============================] - 43s 66ms/step - loss: 293.5488 - mse: 293.5486\n",
            "Epoch 2/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.7302 - mse: 8.7302\n",
            "Epoch 3/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6852 - mse: 8.6852\n",
            "Epoch 4/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6771 - mse: 8.6771\n",
            "Epoch 5/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6620 - mse: 8.6620\n",
            "Epoch 6/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6583 - mse: 8.6583\n",
            "Epoch 7/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6627 - mse: 8.6627\n",
            "Epoch 8/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6414 - mse: 8.6414\n",
            "Epoch 9/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6486 - mse: 8.6486\n",
            "Epoch 10/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6371 - mse: 8.6371\n",
            "Epoch 11/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6430 - mse: 8.6430\n",
            "Epoch 12/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6302 - mse: 8.6302\n",
            "Epoch 13/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6336 - mse: 8.6336\n",
            "Epoch 14/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6127 - mse: 8.6127\n",
            "Epoch 15/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6309 - mse: 8.6309\n",
            "Epoch 16/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6272 - mse: 8.6272\n",
            "Epoch 17/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6161 - mse: 8.6161\n",
            "Epoch 18/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6145 - mse: 8.6145\n",
            "Epoch 19/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6112 - mse: 8.6112\n",
            "Epoch 20/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6249 - mse: 8.6249\n",
            "Epoch 21/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.6028 - mse: 8.6028\n",
            "Epoch 22/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6010 - mse: 8.6010\n",
            "Epoch 23/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6077 - mse: 8.6077\n",
            "Epoch 24/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.5979 - mse: 8.5979\n",
            "Epoch 25/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5940 - mse: 8.5940\n",
            "Epoch 26/40\n",
            "600/600 [==============================] - 40s 67ms/step - loss: 8.5944 - mse: 8.5944\n",
            "Epoch 27/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.6019 - mse: 8.6019\n",
            "Epoch 28/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5824 - mse: 8.5824\n",
            "Epoch 29/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5969 - mse: 8.5969\n",
            "Epoch 30/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5698 - mse: 8.5698\n",
            "Epoch 31/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5862 - mse: 8.5862\n",
            "Epoch 32/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5776 - mse: 8.5776\n",
            "Epoch 33/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5825 - mse: 8.5825\n",
            "Epoch 34/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5724 - mse: 8.5724\n",
            "Epoch 35/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5870 - mse: 8.5870\n",
            "Epoch 36/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5779 - mse: 8.5779\n",
            "Epoch 37/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5805 - mse: 8.5805\n",
            "Epoch 38/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5684 - mse: 8.5684\n",
            "Epoch 39/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5753 - mse: 8.5753\n",
            "Epoch 40/40\n",
            "600/600 [==============================] - 40s 66ms/step - loss: 8.5768 - mse: 8.5768\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2f0a007f8941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# #### train the whole batch for 40 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mNN_regression_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_error_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_regression_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_error_mse\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_regression_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MSE on training data = {} ; MSE of testing data = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_error_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_error_mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1557, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1546, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1535, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1501, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 1327, in mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 100 and 32 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](sequential/dense_1/BiasAdd, mean_squared_error/Cast)' with input shapes: [32,28,100], [32].\n"
          ]
        }
      ]
    }
  ]
}